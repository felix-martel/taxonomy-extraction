{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour débuter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie `libs` contient le code correspondant au mémoire *Extraction de taxonomie par regroupement hiérarchique de plongements vectoriels de graphes de connaissances* (accessible ici : [papers/memoire.pdf](papers/memoire.pdf)). On présente ici un aperçu de ses principales classes et fonctions.\n",
    "\n",
    "**Contenu**\n",
    "\n",
    "- [Graphes de connaissance](#Graphes-de-connaissance)\n",
    "    - [Lecture et sauvegarde d'un graphe](#1.-Lecture-et-sauvegarde-d'un-graphe)\n",
    "    - [Manipulations de base](#2.-Manipulations-basiques)\n",
    "- [Modèles de plongement](#Modèles-de-plongement)\n",
    "- [Taxonomie](#Taxonomie)\n",
    "    - [Généralités sur les arbres](#1.-Généralités-sur-les-arbres)\n",
    "    - [Manipulation de taxonomies](#2.-Manipulation-de-taxonomies)\n",
    "- [Extraction non-expressive](#Extraction-non-expressive)\n",
    "    - [Données](#1.-Données)\n",
    "    - [Extraction](#2.-Extraction)\n",
    "    - [Évaluation](#3.-Évaluation)\n",
    "- [Extraction expressive](#Extraction-expressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphes de connaissance\n",
    "\n",
    "Avant d'appliquer un modèle de plongement ou un algorithme d'extraction taxonomique, il nous faut un graphe de connaissance $\\mathcal{KG} \\subseteq \\mathcal{E \\times R \\times E}$. $\\mathcal{E}$ et $\\mathcal{R}$ représentent, respectivement, l'ensemble des entités et l'ensemble des relations du graphe.\n",
    "\n",
    "Pour représenter et manipuler un tel graphe, on utilise la classe `libs.graph.KnowledgeGraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lecture et sauvegarde d'un graphe\n",
    "\n",
    "Pour lire un graphe de connaissance au format RDF/TTL, on peut utiliser la méthode `build_from_ttl`. Dans l'exemple suivant, on télécharge le fichier TTL contenant les triplets de DB15K, puis on le lit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 99028 triples, 12842 entities and 279 relations.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "from libs.graph import KnowledgeGraph\n",
    "\n",
    "# 1 : Si les données sont absentes, on les télécharge\n",
    "if not os.path.exists(\"db15k.ttl\"):\n",
    "    r = requests.get(\"https://raw.githubusercontent.com/nle-ml/mmkb/master/DB15K/DB15K_EntityTriples.txt\")\n",
    "    with open(\"db15k.ttl\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "# 2 : Lecture du graphe à partir du fichier TTL. shorten=True raccourcit automatiquement les URI avec des préfixes connus\n",
    "kg = KnowledgeGraph.build_from_ttl(\"db15k.ttl\", shorten=True)\n",
    "\n",
    "print(f\"Graph has {len(kg)} triples, {len(kg.ent)} entities and {len(kg.rel)} relations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutefois, il est préférable de stocker les graphes au format [OpenKE](http://openke.thunlp.org/static/notes/data.html). Dans le format OpenKE, chaque entité est associée à un identifiant entier compris entre $0$ et $|\\mathcal{E}|-1$, et chaque relation est associée à un identifiant entier compris entre $0$ et $|\\mathcal{R}|-1$. Le format OpenKE consiste en cinq fichiers :\n",
    "\n",
    "- `ent2id.txt` et `rel2id.txt` stockent les URI et les identifiants des entités et des relations, respectivement. La première ligne du fichier indique le nombre d'éléments contenus dans le fichier (c'est-à-dire $|\\mathcal{E}$ et $\\mathcal{R}|$, respectivement); chacune des lignes suivantes contient une URI et son identifiant, séparés par une espace.\n",
    "\n",
    "- `test2id.txt`, `train2id.txt`, `val2id.txt` contiennent les triplets du graphe. La première ligne indique le nombre de triplets du fichier. Chaque ligne contient un triplet $(h, t, r)$ (attention à l'ordre !) dont les éléments sont représentés par leurs identifiants et séparés par une espace.\n",
    "\n",
    "Pour stocker notre graphe de connaissance dans ce format, on dispose de la méthode `to_dir`, qui prend comme argument le chemin du dossier dans lequel on souhaite stocker le graphe. Une fois le graphe sauvegardé, on peut lui donner un nom et l'**enregistrer** avec la méthode `register`. Cela permet ensuite de le charger plus facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.to_dir(\"data/graph/db15k\")\n",
    "kg.register(\"db15k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on a enregistré le graphe sous le nom `\"db15k\"`. Par la suite, on pourra le charger avec la commande `from_dir`, simplement en donnant ce nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triples: 100%|███████████████████████████████████████████████████████████████| 89197/89197 [00:00<00:00, 113786.40it/s]\n"
     ]
    }
   ],
   "source": [
    "del kg\n",
    "\n",
    "kg = KnowledgeGraph.from_dir(\"db15k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut enregistrer un graphe à la main, en l'ajoutant au fichier `resources.json`. On peut également passer à la méthode `from_dir` le chemin vers un dossier contenant un graphe, sans que celui-ci soit enregistré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Le *parser* utilisé pour lire les fichiers TTL est assez basique. Si votre graphe n'est pas au format TTL ou résiste à `build_from_ttl`, utilisez une librairie dédiée comme [`rdflib`](https://pypi.org/project/rdflib/) et créez le graphe avec la méthode `from_triples`. Voici un exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 62 triples, 55 entities and 35 relations.\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"http://bigasterisk.com/foaf.rdf\")\n",
    "triples = [(str(h), str(r), str(t)) for h, r, t in g]\n",
    "kg = KnowledgeGraph.from_triples(triples)\n",
    "\n",
    "print(f\"Graph has {len(kg)} triples, {len(kg.ent)} entities and {len(kg.rel)} relations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Manipulations basiques\n",
    "\n",
    "\n",
    "Dans la suite, on utilise le graphe «jouet» fourni avec la librairie. C'est un sous-ensemble restreint de DBpédia, contenant environ 300 000 triplets, qui peut être chargé avec la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triples: 100%|██████████████████████████████████████████████████████████████| 316114/316114 [00:03<00:00, 91951.97it/s]\n"
     ]
    }
   ],
   "source": [
    "kg = KnowledgeGraph.from_dir(\"toy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un graphe est constitué d'un ensemble d'entités `kg.ent` et d'un ensemble de relations `kg.rel`, reliées entre elles. Pour passer de l'URI à l'identifiant et inversement, on utilise `to_id` et `to_name`. `kg.ent` et `kg.rel` supportent les tests d'appartenance avec le mot-clé `in`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "dbr:United_States <--> 74\n",
      "dbo:team <--> 0\n"
     ]
    }
   ],
   "source": [
    "print(\"dbr:United_States\" in kg.ent)\n",
    "print(\"dbr:United_States <-->\", kg.ent.to_id(\"dbr:United_States\"))\n",
    "print(kg.rel.to_name(0), \"<--> 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rechercher des triplets dans le graphe, on utilise la méthode `find_triples`. Elle prend trois arguments optionnels qui sont `h`, `r` et `t`, correspondant respectivement au sujet, à la relation et à l'objet du triplet à rechercher; ces trois arguments peuvent prendre indifférement des URI ou des identifiants. Par défaut, les triplets sont retournés au format identifiant, mais on peut renvoyer des strings en choisissant `as_string=True`. On peut choisir de limiter le nombre de résultats avec `max_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"dbr:Seven_Years'_War\", 'dbo:commander', 'dbr:Charles,_Prince_of_Soubise'),\n",
       " (\"dbr:Seven_Years'_War\", 'dbo:commander', 'dbr:Frederick_the_Great'),\n",
       " (\"dbr:Seven_Years'_War\",\n",
       "  'dbo:commander',\n",
       "  'dbr:Pedro_Pablo_Abarca_de_Bolea,_10th_Count_of_Aranda'),\n",
       " (\"dbr:Seven_Years'_War\", 'dbo:commander', 'dbr:Louis_XV_of_France'),\n",
       " (\"dbr:Seven_Years'_War\",\n",
       "  'dbo:commander',\n",
       "  'dbr:Duke_Ferdinand_of_Brunswick-Wolfenbüttel'),\n",
       " (\"dbr:Seven_Years'_War\", 'dbo:commander', 'dbr:Robert_Clive'),\n",
       " (\"dbr:Seven_Years'_War\",\n",
       "  'dbo:commander',\n",
       "  'dbr:Jeffery_Amherst,_1st_Baron_Amherst'),\n",
       " (\"dbr:Seven_Years'_War\", 'dbo:commander', 'dbr:Alexander_Buturlin'),\n",
       " (\"dbr:Seven_Years'_War\", 'dbo:commander', 'dbr:Pedro_Antonio_de_Cevallos'),\n",
       " (\"dbr:Seven_Years'_War\",\n",
       "  'dbo:commander',\n",
       "  'dbr:Prince_Henry_of_Prussia_(1726–1802)')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.find_triples(h=\"dbr:Seven_Years'_War\", r=\"dbo:commander\", as_string=True, max_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutôt que de renvoyer les triplets complets, on peut choisir d'obtenir uniquement les sujets, les objets ou les relations avec respectivement `heads()`, `tails()` et `relations()`, qui ont la même signature que `find_triples`.\n",
    "\n",
    "Par exemple, on peut afficher l'ensemble des personnes nées au Québec avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dbr:Dalia_Shusterman',\n",
       " 'dbr:Roméo_Beaudry',\n",
       " 'dbr:Francis_Lessard',\n",
       " 'dbr:Carol_Vadnais',\n",
       " 'dbr:Gilles_Ste-Croix',\n",
       " 'dbr:Pat_Burns',\n",
       " 'dbr:Marlene_Jennings',\n",
       " 'dbr:Melissa_Altro',\n",
       " 'dbr:CFCF_(musician)',\n",
       " 'dbr:Albert_Gervais',\n",
       " 'dbr:Lorraine_Desmarais',\n",
       " 'dbr:Robert_MacNeil',\n",
       " 'dbr:Stéfanie_Tremblay']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.heads(r=\"dbo:birthPlace\", t=\"dbr:Quebec\", as_string=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou l'ensemble des liens qui unissent Baltacı à l'Empire ottoman :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dbo:birthPlace', 'dbo:deathPlace', 'dbo:country', 'dbo:nationality']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.relations(h=\"dbr:Baltacı_Mehmet_Pasha\", t=\"dbr:Ottoman_Empire\", as_string=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour explorer facilement le voisinage d'une entité, on utilisera la méthode `print_relations()`. Par défaut, elle affiche toutes les relations dont l'entité choisie est sujet ou objet. Ce comportement peut être changé avec `inverse=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbr:Leon_Trotsky\n",
      "\t rdf:type\n",
      "\t\t dbo:Agent\n",
      "\t\t dbo:Person\n",
      "\t\t dbo:OfficeHolder\n",
      "\t is dbo:commander of\n",
      "\t\t dbr:Polish–Soviet_War\n",
      "\t\t dbr:July_Days\n",
      "\t\t dbr:Eastern_Front_of_the_Russian_Civil_War\n",
      "\t\t dbr:Russian_Revolution\n"
     ]
    }
   ],
   "source": [
    "kg.print_relations(\"dbr:Leon_Trotsky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Un graphe de connaissance peut consommer beaucoup de mémoire. La version complète de DBpédia demande environ 20 Go de RAM, et encore, en utilisant `lightweight=True` lors de sa lecture (ce qui permet d'ignorer les relations `rdfs:label`, `foaf:name` et `dcterms:description` ainsi que les types extérieurs comme `yago:WikiCat` : ces données sont inutiles pour beaucoup d'usages et coûtent cher en mémoire). La lecture de ce graphe depuis le disque demande entre sept et neuf minutes. À noter que, dans mes essais, l'implémentation de `rdflib` était encore plus inefficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de plongement\n",
    "\n",
    "Pour entraîner les modèles de plongement, j'ai eu recours à [OpenKE](https://github.com/thunlp/OpenKE) (d'où le choix de ce format pour stocker les graphes). Toutefois, depuis cette époque, de nouvelles librairies sont sorties, qui sont potentiellement plus efficaces. Voir par exemple [TorchKGE](https://pypi.org/project/torchkge/).\n",
    "\n",
    "Pour ce projet, il est attendu que les plongements soient représentés par une matrice de dimension $n \\times d$ avec $n = |\\mathcal{E}|$ et $d$ la dimension des plongements, elle-même stockée dans un array numpy au format `.npy`. On peut ainsi la charger avec `numpy.load()`.\n",
    "\n",
    "Comme les graphes de connaissance, les modèles de plongement peuvent être ajoutés au fichier `resources.json`, ce qui permet de les charger plus facilement. On peut également fournir un modèle par défaut avec la clé `\"default\"`. Par défaut, on dispose d'un modèle TransE de dimension 50 entraîné sur le graphe «jouet»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54795, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libs import embeddings\n",
    "\n",
    "E = embeddings.load(\"toy\")\n",
    "E.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomie\n",
    "\n",
    "Une taxonomie $T$ est un arbre orienté dont les arêtes représentent des relations de subsomption. Elle est représentée par la classe `libs.taxonomy.Taxonomy`, qui hérite de `libs.tree.Node`, la classe générique qui nous sert à représenter les arbres. Commençons par présenter cette première classe, qui sert aussi à représenter les arbres de clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Généralités sur les arbres\n",
    "\n",
    "On identifie un arbre est représenté par la classe `Node`. Essentiellement, un arbre `A` est constitué d'un identifiant `A.id`, et de sous-arbres (stockés dans `A.children`). Si `A.children` est vide, alors `A` est une feuille. `A` contient également un pointeur vers son parent immédiat `A.parent`, qui vaut `None` si `A` n'a pas de parent (*i.e.* `A` est une racine de l'arbre). Autrement dit, on identifie «nœud $A$» et «sous-arbre ayant $A$ pour racine» (noté $X[A]$ dans mon mémoire).\n",
    "\n",
    "Un nœud possède également un nom `A.name`, qui par défaut est égal à `str(A.id)`. N'importe quel objet *hashable* peut servir d'identifiant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manipulations basiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ┌B\n",
      " A┤\n",
      "  ├D\n",
      "  └C\n",
      "  ┌B\n",
      " A┤\n",
      "  └C\n"
     ]
    }
   ],
   "source": [
    "from libs.tree import Node\n",
    "\n",
    "A = Node(\"A\")\n",
    "\n",
    "# Ajout d'enfants\n",
    "A.add_many([\"B\", \"C\", \"D\"])\n",
    "A.print()\n",
    "\n",
    "# Retrait d'un enfant\n",
    "A.remove(\"D\")\n",
    "A.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut accéder à un nœud d'un arbre à l'aide de son identifiant, en utilisant la notation crochets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ┌C\n",
      " A┤\n",
      "  │ ┌B1\n",
      "  │ ├B2\n",
      "  └B┤\n",
      "    ├B3┐\n",
      "    │  └B31\n",
      "    └B4\n",
      "  ┌B1\n",
      "  ├B2\n",
      " B┤\n",
      "  ├B3┐\n",
      "  │  └B31\n",
      "  └B4\n"
     ]
    }
   ],
   "source": [
    "B = A[\"B\"]\n",
    "B.add_many([\"B1\", \"B2\", \"B3\", \"B4\"])\n",
    "B[\"B3\"].add(\"B31\")\n",
    "\n",
    "A.print()\n",
    "B.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un nœud expose les attributs `is_leaf`, `is_root`, `n_children` et `siblings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : root=True, leaf=False, nb of children=2, siblings=\n",
      "B : root=False, leaf=False, nb of children=4, siblings=C\n",
      "B4 : root=False, leaf=True, nb of children=0, siblings=B1B2B3\n",
      "B31 : root=False, leaf=True, nb of children=0, siblings=\n"
     ]
    }
   ],
   "source": [
    "for node in [\"A\", \"B\", \"B4\", \"B31\"]:\n",
    "    node = A[node]\n",
    "    print(node, \" : \",\n",
    "          \"root=\", node.is_root, \n",
    "          \", leaf=\", node.is_leaf, \n",
    "          \", nb of children=\", node.n_children, \n",
    "          \", siblings=\", *node.siblings(),\n",
    "          sep=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tester si un nœud est un descendant d'un autre nœud avec `<` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A[\"B31\"]\n",
    "C < B < A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parcours**\n",
    "\n",
    "Un arbre est itérable. L'itération se fait sur tous les nœuds de l'arbre, racine comprise. Si l'on souhaite exclure la racine, on peut utiliser `iter_children()` (le nom est ambigu, car `Node.iter_children()` est différent de `iter(Node.children)`. Un nom plus approprié serait `iter_successors`). L'itération a lieu sans garantie sur l'ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root included: A B C B1 B2 B3 B4 B31\n",
      "Root excluded: B C B1 B2 B3 B4 B31\n"
     ]
    }
   ],
   "source": [
    "print(\"Root included:\", *(node for node in A))\n",
    "print(\"Root excluded:\", *A.iter_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également effectuer un parcours en largeur (BFS, pour *Breadth First Search*) et un parcours en profondeur (DFS, pour *Depth First Search*) de l'arbre avec les méthodes `Node.bfs()` et `Node.dfs()`. Dans les deux cas, on peut spécifier une profondeur maximale de recherche avec `max_depth`, un nombre maximal de nœuds avec `max_nodes`, et enfin une condition d'arrêt personnalisée avec `halting_func` (qui prend un nœud en entrée et retourne un booléen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS: A C B B4 B3 B31 B2 B1\n",
      "BFS: A B C B1 B2 B3 B4 B31\n"
     ]
    }
   ],
   "source": [
    "print(\"DFS:\", *A.dfs())\n",
    "print(\"BFS:\", *A.bfs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Création, lecture, écriture**\n",
    "\n",
    "On peut créer et modifier un arbre avec les méthodes `add`, `add_many`, `remove`, `remove_many` présentées plus haut. Un autre moyen, souvent plus efficace, pour créer un arbre, consiste à fournir la liste de ses arêtes. Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌a2┐\n",
      "     │  └b2\n",
      "     ├a3┐\n",
      "     │  └b3\n",
      " root┤\n",
      "     └a1┐\n",
      "        │  ┌c1\n",
      "        └b1┤\n",
      "           └c2\n"
     ]
    }
   ],
   "source": [
    "edges = [\n",
    "    (\"c1\", \"b1\"),\n",
    "    (\"c2\", \"b1\"),\n",
    "    (\"b1\", \"a1\"),\n",
    "    (\"b2\", \"a2\"),\n",
    "    (\"b3\", \"a3\"),\n",
    "    (\"a1\", \"root\"),\n",
    "    (\"a2\", \"root\"),\n",
    "    (\"a3\", \"root\")\n",
    "]\n",
    "\n",
    "tree = Node.from_edges(edges)\n",
    "tree.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inversement, on peut obtenir la liste des arêtes à partir d'un arbre, avec la méthode `Node.to_edges()`. On peut également sauvegarder un arbre dans un fichier avec `Node.to_file()` and `Node.from_file()`. Dans les deux cas, un fonction `preprocess` peut être appelée pour transformer un identifiant en chaîne de caractère, ou une chaîne de caractère en identifiant, ce qui permet de stocker des nœuds non-textuels avec des méthodes de sérialisation/désérialisation.\n",
    "\n",
    "Prenons l'exemple d'un arbre dont les nœuds sont des entiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ┌2\n",
      "  ├3\n",
      " 0┤\n",
      "  │ ┌4\n",
      "  └1┤\n",
      "    └5\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "tree = Node.from_edges([(4, 1), (5, 1), (1, 0), (2, 0), (3, 0)])\n",
    "tree.print()\n",
    "print(type(tree.id))\n",
    "\n",
    "tree.to_file(\"dummy_tree.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Sans désérialisation\n",
    "tree2 = Node.from_file(\"dummy_tree.txt\")\n",
    "print(type(tree2.id)) # str au lieu de int\n",
    "\n",
    "# Avec désérialisation\n",
    "tree3 = Node.from_file(\"dummy_tree.txt\", preprocess=int)\n",
    "print(type(tree3.id)) # int, comme prévu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manipulations d'arbres**\n",
    "\n",
    "On peut détacher un sous-arbre d'un arbre existant avec `Node.detach()`, attacher deux arbres ensembles avec `Node.attach()` et `Node.move()` pour déplacer un sous-arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = dict(figure_params=dict(figsize=(4, 2)))\n",
    "tree = Node.from_edges([(4, 1), (5, 1), (1, 0), (2, 0), (3, 0)])\n",
    "tree.plot(**params)\n",
    "\n",
    "other = Node.from_edges([(8, 6), (6, 2), (7, 2)])\n",
    "other.plot(**params)\n",
    "other.attach(tree[2])\n",
    "\n",
    "tree.plot(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Manipulation de taxonomies\n",
    "\n",
    "`libs.taxonomy.Taxonomy` reprend tous les principes précédents (avec `from_axioms` et `to_axioms` à la place de `from_edges` et `to_edges`) et ajoute quelques attributs supplémentaires comme `Taxonomy.hierarchy` (pour afficher toutes les superclasses d'une classe donnée).\n",
    "\n",
    "Pour créer une taxonomie à partir d'une ontologie `OWL`, il suffit de récupérer les liens `rdfs:subClassOf`, comme dans l'exemple suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dbo:ReligiousBuilding', 'dbo:Building'), ('dbo:Ship', 'schema:Product'), ('dbo:Ship', 'dbo:MeanOfTransportation'), ('dbo:Locality', 'dbo:PopulatedPlace'), ('dbo:Entomologist', 'dbo:Scientist'), ('dbo:PopulatedPlace', 'dbo:Place'), ('dbo:Instrument', 'dbo:Device'), ('dbo:Instrument', 'schema:Product'), ('dbo:Lighthouse', 'dbo:Tower'), ('dbo:Blazon', 'owl:Thing')]\n",
      "785 classes\n",
      "Level 0: __root__\n",
      "Level 1: schema:MusicRecording, http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#SocialPerson, schema:Festival, http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#InformationObject, http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#Event and 11 others\n",
      "...\n",
      "Level 7: dbo:SubMunicipality, dbo:Prefecture, dbo:Canton, dbo:Province, dbo:Arrondissement and 16 others\n",
      "Level 8: dbo:HistoricalDistrict, dbo:HistoricalProvince, dbo:OverseasDepartment, dbo:FormerMunicipality\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import requests\n",
    "from rdflib import Graph\n",
    "\n",
    "from libs.taxonomy import Taxonomy\n",
    "from libs.graph import KnowledgeGraph\n",
    "from libs.graph.uri import shorten\n",
    "\n",
    "# On récupère l'URL de la taxonomie DBpédia sur la page : https://databus.dbpedia.org/denis/ontology/dbo-snapshots/\n",
    "DBO_URL = \"https://raw.githubusercontent.com/dbpedia/ontology-tracker/7157d38fbde8b942e9807e722586d593f4d31451/databus/dbpedia/ontology/dbo-snapshots/dbo-snapshots.ttl\"\n",
    "g = Graph()\n",
    "g.parse(DBO_URL, format=\"ttl\")\n",
    "\n",
    "# shorten sert à raccourcir les URI avec des préfixes connus\n",
    "triples = [(shorten(str(h)), shorten(str(r)), shorten(str(t))) for h, r, t in g]\n",
    "dbo = KnowledgeGraph.from_triples(triples)\n",
    "axioms = [(h, t) for h, _, t in dbo.find_triples(r=\"rdfs:subClassOf\", as_string=True)]\n",
    "\n",
    "# Création de la taxonomie\n",
    "T = Taxonomy.from_edges(axioms, add_root=\"__root__\")\n",
    "\n",
    "print(T.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction non-expressive\n",
    "\n",
    "\n",
    "### 1. Données\n",
    "\n",
    "\n",
    "L'extraction non-expressive nécessite un jeu d'entraînement $\\mathcal{D} \\subseteq \\mathbb{R}^d \\times \\mathcal{T}$, constitué de plongements vectoriels typés. Ce jeu d'entraînement est représenté par la classe `libs.dataset.Dataset`. Trois fonctions peuvent aider à en créer un :\n",
    "- `create_from_classes`: prend en entrée la liste de classes $\\mathcal{T}$ (ou *types*) qui doivent figurer dans les données. Des instances de chaque classe sont prélevées aléatoirement dans le graphe pour constituer les données.\n",
    "- `create_from_instances`: prend en entrée une liste d'entités (représentées par leurs identifiants). Un de leur type est choisi aléatoirement comme label.\n",
    "- `create_from_typed_instances` : fonction auxiliaire qui prend en entrée une liste d'entités et une liste de types.\n",
    "\n",
    "Dans les deux premiers cas, la création d'un `Dataset` suppose d'avoir accès à un graphe de connaissance : soit pour trouver des instances d'une classe donnée, soit pour trouver la classe d'une entité donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triples: 100%|██████████████████████████████████████████████████████████████| 316114/316114 [00:03<00:00, 98671.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "316114"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libs.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph.from_dir(\"toy\")\n",
    "len(kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici trois exemples de création de `Dataset` :\n",
    "- 1 000 instances de chacune des classes `Organisation`, `Person`, `Event`, `Place`\n",
    "- Mêmes classes, mais nombre d'instances variable\n",
    "- Création d'un dataset contenant uniquement des personnes nées aux États-Unis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (4 classes, 4000 instances):\n",
      "---\n",
      "dbo:Organisation   1000\n",
      "dbo:Person         1000\n",
      "dbo:Event          1000\n",
      "dbo:Place          1000\n",
      "...\n",
      "Dataset (4 classes, 2100 instances):\n",
      "---\n",
      "dbo:Place          1000\n",
      "dbo:Event          500\n",
      "dbo:Organisation   300\n",
      "dbo:Person         300\n",
      "...\n",
      "Dataset (18 classes, 78 instances):\n",
      "---\n",
      "dbo:Person              29\n",
      "dbo:Agent               22\n",
      "dbo:OfficeHolder        5\n",
      "dbo:Athlete             4\n",
      "dbo:IceHockeyPlayer     2\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import libs.dataset as data\n",
    "from libs.dataset import Dataset\n",
    "\n",
    "# Création à partir des classes\n",
    "df1 = data.create_from_classes(kg, classes=[\"dbo:Organisation\", \"dbo:Person\", \"dbo:Event\", \"dbo:Place\"], class_size=1000)\n",
    "print(df1.summary())\n",
    "\n",
    "df2 = data.create_from_classes(kg, \n",
    "                               classes=[\"dbo:Organisation\", \"dbo:Person\", \"dbo:Event\", \"dbo:Place\"],\n",
    "                              class_size=[300, 300, 500, 1000])\n",
    "print(df2.summary())\n",
    "\n",
    "# Création à partir des instances\n",
    "df3 = data.create_from_instances(kg, instances=kg.heads(r=\"dbo:birthPlace\", t=\"dbr:United_States\"))\n",
    "print(df3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment déterminer le nombre d'instances à prélever pour chaque classe ?\n",
    "\n",
    "Supposons qu'il y ait $N_{unique}$ types distincts, que le cumul des effectifs de chaque classe soit noté $N_{total}$, et que l'on cherche à prélever $N_{target}$ échantillons au total. Pour déterminer le nombre d'entités à prélever pour un type donné ayant $m$ éléments, on peut imaginer trois stratégies :\n",
    "\n",
    "- Même nombre d'éléments pour chaque classe : $N_{unif} = \\frac{N_{unique}}{N_{target}}$\n",
    "\n",
    "- Nombre d'éléments proportionnel à l'effectif réel de la classe : $N_{prop} = m \\cdot \\frac{N_{target}}{N_{total}}$\n",
    "\n",
    "- Mélange des deux précédents : $N_{mix} = \\alpha N_{unif} + (1 - \\alpha) N_{prop}$ avec $\\alpha \\in [0, 1]$ un paramètre\n",
    "\n",
    "Dans la stratégie uniforme, toutes les classes ont le même effectif, ce qui biaise les données vers les classes rares. Dans la stratégie proportionnelle, étant donnés les déséquilibres entre effectifs (en gros : 1,5M d'agents, 1,3M de personnes, 800k lieux, 300k athlètes, donc rapidement des différences de plusieurs ordres de grandeur), on a un gros biais vers les classes fréquentes. On peut affiner avec un sampling log-proportionnel, ou mieux avec un mélange linéaire/log-proportionnel.\n",
    "\n",
    "Voir le notebook `08_Subtaxonomies_Creation.ipynb` pour plus de détails à ce sujet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sauvegardes des données**\n",
    "\n",
    "Un `Dataset` peut être enregistré sur le disque avec `save()` et lu avec `load()`. Il peut être enregistré dans `resources.json` pour être chargé plus facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (15 classes, 78 instances):\n",
      "---\n",
      "dbo:Person              28\n",
      "dbo:Agent               27\n",
      "dbo:Athlete             4\n",
      "dbo:OfficeHolder        4\n",
      "dbo:Judge               2\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "df.save(\"data/dataset/US_people\")\n",
    "df.register(\"data_US\")\n",
    "del df\n",
    "\n",
    "df = Dataset.load(\"data_US\")\n",
    "print(df.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extraction\n",
    "\n",
    "On suppose que l'on dispose d'un *dataset* et d'une matrice de plongements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.dataset import Dataset\n",
    "import libs.embeddings as embeddings\n",
    "\n",
    "data = Dataset.load(\"toy\")\n",
    "E = embeddings.load(\"toy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première étape, le regroupement hiérarchique des plongements, effectué avec la fonction `clusterize` du module `libs.cluster`, qui renvoie un arbre de clustering représenté par la classe `Cluster` de ce même module.\n",
    "\n",
    "Le regroupement se base sur la méthode externe [`sklearn.cluster.AgglomerativeClustering`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html). En particulier, on peut spécifier les paramètres `affinity` (distance à utiliser, à choisir parmi *euclidean*, *l1*, *l2*,\n",
    "        *manhattan*, *cosine*) et `linkage` (critère de liaison, au choix : *ward*, *complete*, *average*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ┌C<3978>\n",
      "        ┌C<3995>┤\n",
      "        │       └C<3994>\n",
      " C<3998>┤\n",
      "        │       ┌C<3990>\n",
      "        └C<3997>┤\n",
      "                └C<3996>\n"
     ]
    }
   ],
   "source": [
    "from libs.cluster import clusterize\n",
    "\n",
    "clu = clusterize(data, E)\n",
    "clu.print(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seconde étape, calculer les scores $F_1$ de chaque cluster :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.metrics import f_score\n",
    "\n",
    "F = clu.get_func_matrix(f_score, class_counts=clu.data.class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième étape, associer les types aux clusters, selon la méthode MLI (*hard mapping*) ou MLM (*soft mapping*). Pour cela, on utilise la fonction `libs.extraction.extract_axioms()` avec le paramètre `method=\"hard\"` ou `method=\"soft\"`. Dans ce dernier cas, on peut alors préciser les paramètres `threshold` ($\\delta$ dans mon mémoire) et `gamma` ($\\beta$ dans mon mémoire : attention au changement de nom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.extraction import extract_axioms\n",
    "\n",
    "pred_axioms = extract_axioms(F, method=\"soft\", root=clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour simplifier le processus, on peut utiliser la classe `TaxonomyExtractor` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.extraction import TaxonomyExtractor\n",
    "\n",
    "ext = TaxonomyExtractor(data, E, method=\"soft\", \n",
    "                        clustering_params=dict(affinity=\"cosine\", linkage=\"average\"), \n",
    "                        mapping_params=dict(threshold=0.1, beta=100)\n",
    "                       )\n",
    "\n",
    "predicted = ext.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Évaluation\n",
    "\n",
    "Pour comparer les atomes extraits avec une taxonomie de référence, on recommande d'utiliser la fonction `libs.taxonomy.evaluate_full()`, qui permet d'effectuer à la fois l'évaluation directe et transitive (cf. la section 4.3.2 du mémoire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "closure  \tno    \t\tyes\n",
      "---------------------------------------\n",
      "precision\t80.00%\t\t87.50%\n",
      "recall   \t80.00%\t\t100.00%\n",
      "f1       \t80.00%\t\t93.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from libs.taxonomy import evaluate_full\n",
    "\n",
    "\n",
    "pred = [(\"B\", \"A\"), (\"C\", \"A\"), (\"D\", \"B\"), (\"E\", \"B\"), (\"F\", \"C\")]\n",
    "true = [(\"B\", \"A\"), (\"C\", \"A\"), (\"D\", \"A\"), (\"E\", \"B\"), (\"F\", \"C\")]\n",
    "\n",
    "res = evaluate_full(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction expressive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triples: 100%|██████████████████████████████████████████████████████████████| 316114/316114 [00:03<00:00, 89514.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from libs.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph.from_dir(\"toy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la classe `libs.expressive.ExpressiveExtractor` pour procéder à l'extraction. Dans sa syntaxe la plus simple, il s'utilise comme suit :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from libs.expressive import ExpressiveExtractor\n",
    "\n",
    "ext = ExpressiveExtractor(kg)\n",
    "T_pred = ext.run()\n",
    "T_pred.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'extracteur nécessite au minimum l'accès à un `KnowledgeGraph`; on peut également lui passer un `GraphSampler` (du module `libs.sampling`), pour l'étape de prélèvement. On peut changer les paramètres avec un objet `Params` : le plus simple est de partir de `libs.expressive.BASE_PARAMS` et de le modifier. Ces paramètres sont automatiquement sauvegardés dans un fichier JSON lors de l'initialisation de l'extracteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'results/taxonomy/auto\\taxonomy_5s_0922_18h01' already exists.\n",
      "Override ? y/[n]y\n",
      "18:01:52 - INFO : Initialisation done.\n",
      "18:01:52 - INFO : Initialisation done.\n",
      "18:01:52 - INFO : STEP 0: starting with axiom ⊤\n",
      "18:01:52 - INFO : STEP 0: starting with axiom ⊤\n",
      "18:01:53 - INFO : Subclasses found: dbo:Settlement∨dbo:Organisation, ∃dbo:country.dbo:Location\n",
      "18:01:53 - INFO : Subclasses found: dbo:Settlement∨dbo:Organisation, ∃dbo:country.dbo:Location\n",
      "18:01:53 - INFO : STEP 1: starting with axiom dbo:Settlement∨dbo:Organisation\n",
      "18:01:53 - INFO : STEP 1: starting with axiom dbo:Settlement∨dbo:Organisation\n",
      "18:01:54 - INFO : Subclasses found: ∃dbo:country.dbo:Country, ∃dbo:country.dbo:Place\n",
      "18:01:54 - INFO : Subclasses found: ∃dbo:country.dbo:Country, ∃dbo:country.dbo:Place\n",
      "18:01:54 - INFO : STEP 2: starting with axiom ∃dbo:country.dbo:Location\n",
      "18:01:54 - INFO : STEP 2: starting with axiom ∃dbo:country.dbo:Location\n",
      "18:01:56 - INFO : Subclasses found: ∃dbo:isPartOf.dbo:PopulatedPlace, ∃dbo:areaTotal.{xsd:double}\n",
      "18:01:56 - INFO : Subclasses found: ∃dbo:isPartOf.dbo:PopulatedPlace, ∃dbo:areaTotal.{xsd:double}\n",
      "18:01:56 - INFO : STEP 3: starting with axiom ∃dbo:country.dbo:Country\n",
      "18:01:56 - INFO : STEP 3: starting with axiom ∃dbo:country.dbo:Country\n",
      "18:01:57 - INFO : Subclasses found: dbo:EducationalInstitution∨∃dbo:elevation.{xsd:double}, dbo:EducationalInstitution∨dbo:Organisation\n",
      "18:01:57 - INFO : Subclasses found: dbo:EducationalInstitution∨∃dbo:elevation.{xsd:double}, dbo:EducationalInstitution∨dbo:Organisation\n",
      "18:01:57 - INFO : STEP 4: starting with axiom ∃dbo:country.dbo:Place\n",
      "18:01:57 - INFO : STEP 4: starting with axiom ∃dbo:country.dbo:Place\n",
      "18:01:59 - INFO : Subclasses found: dbo:EducationalInstitution∨dbo:Settlement, dbo:EducationalInstitution∨dbo:Organisation\n",
      "18:01:59 - INFO : Subclasses found: dbo:EducationalInstitution∨dbo:Settlement, dbo:EducationalInstitution∨dbo:Organisation\n",
      "18:01:59 - INFO : STEP 5: starting with axiom ∃dbo:isPartOf.dbo:PopulatedPlace\n",
      "18:01:59 - INFO : STEP 5: starting with axiom ∃dbo:isPartOf.dbo:PopulatedPlace\n",
      "18:02:01 - INFO : Subclasses found: ∃dbo:areaLand.{xsd:double}, ∃dbo:areaWater.{xsd:double}\n",
      "18:02:01 - INFO : Subclasses found: ∃dbo:areaLand.{xsd:double}, ∃dbo:areaWater.{xsd:double}\n",
      "18:02:01 - INFO : Max. number of clustering steps reached (N=5)\n",
      "18:02:01 - INFO : Max. number of clustering steps reached (N=5)\n",
      "                              ┌⊤∧∃dbo:country.dbo:Location∧∃dbo:areaTotal.{xsd:double}\n",
      "  ┌⊤∧∃dbo:country.dbo:Location┤\n",
      "  │                           │                                                            ┌⊤∧∃dbo:country.dbo:Location∧∃dbo:isPartOf.dbo:PopulatedPlace∧∃dbo:areaLand.{xsd:double}\n",
      "  │                           └⊤∧∃dbo:country.dbo:Location∧∃dbo:isPartOf.dbo:PopulatedPlace┤\n",
      "  │                                                                                        └⊤∧∃dbo:country.dbo:Location∧∃dbo:isPartOf.dbo:PopulatedPlace∧∃dbo:areaWater.{xsd:double}\n",
      " ⊤┤\n",
      "  │                                                                                                ┌⊤∧(dbo:Settlement∨dbo:Organisation)∧∃dbo:country.dbo:Country∧(dbo:EducationalInstitution∨∃dbo:elevation.{xsd:double})\n",
      "  │                                   ┌⊤∧(dbo:Settlement∨dbo:Organisation)∧∃dbo:country.dbo:Country┤\n",
      "  │                                   │                                                            └⊤∧(dbo:Settlement∨dbo:Organisation)∧∃dbo:country.dbo:Country∧(dbo:EducationalInstitution∨dbo:Organisation)\n",
      "  └⊤∧(dbo:Settlement∨dbo:Organisation)┤\n",
      "                                      │                                                          ┌⊤∧(dbo:Settlement∨dbo:Organisation)∧∃dbo:country.dbo:Place∧(dbo:EducationalInstitution∨dbo:Settlement)\n",
      "                                      └⊤∧(dbo:Settlement∨dbo:Organisation)∧∃dbo:country.dbo:Place┤\n",
      "                                                                                                 └⊤∧(dbo:Settlement∨dbo:Organisation)∧∃dbo:country.dbo:Place∧(dbo:EducationalInstitution∨dbo:Organisation)\n"
     ]
    }
   ],
   "source": [
    "from libs.expressive import ExpressiveExtractor\n",
    "from libs.expressive import BASE_PARAMS as params\n",
    "from libs.sampling import NaiveGraphSampler\n",
    "from copy import deepcopy\n",
    "\n",
    "params.threshold.adaptative = False\n",
    "params.halting.max_clustering_steps = 5\n",
    "\n",
    "ext = ExpressiveExtractor(kg, sampler=NaiveGraphSampler(kg))\n",
    "T_pred = ext.run(10)\n",
    "T_pred.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axiomes\n",
    "\n",
    "Les axiomes sont représentés par des sous-classes de `libs.axiom.Axiom`. Un axiome peut être *atomique* ou *composé*. Dans le premier cas, il appartient à l'un de ces types :\n",
    "- axiome universel $\\top$ ou `TopAxiom`\n",
    "- classe nommée $C$ ou `Concept(C)`, avec $C \\in \\mathcal{T}$\n",
    "- classe singleton $\\{e\\}$ ou `Concept({e})`, avec $e \\in \\mathcal{E}$\n",
    "- restriction existentielle $\\exists R.C$, avec $R$ une relation et $C$ appartenant à l'un des trois types ci-dessus\n",
    "\n",
    "Dans le second cas, un axiome est représenté par `NaryAxiom` : c'est la combinaison de $N$ axiomes (qui peuvent eux-mêmes être des axiomes composés) au moyen d'un certain opérateur logique (par exemple, la conjonction, la négation ou la disjonction). $N$ est appelé l'*arité* de l'opérateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Axiomes atomiques==\n",
      "Concept(⊤) \t ⊤\n",
      "Concept(dbo:Settlement) \t dbo:Settlement\n",
      "Concept({<STRING>}) \t {<STRING>}\n",
      "Existential(∃dbo:postalCode.{<STRING>}) \t ∃dbo:postalCode.{<STRING>}\n",
      "Existential(∃dbo:country.⊤) \t ∃dbo:country.⊤\n",
      "\n",
      "==Axiomes composés==\n",
      "NaryAxiom(dbo:Settlement∧∃dbo:postalCode.{<STRING>})\n",
      "NaryAxiom(dbo:Settlement∧∃dbo:country.⊤)\n",
      "NaryAxiom((dbo:Settlement∧∃dbo:postalCode.{<STRING>})∨(dbo:Settlement∧∃dbo:country.⊤))\n",
      "NaryAxiom(¬{<STRING>})\n"
     ]
    }
   ],
   "source": [
    "from libs.axiom import Existential, Concept, TopAxiom\n",
    "\n",
    "print(\"==Axiomes atomiques==\")\n",
    "TO = TopAxiom\n",
    "CO = Concept(\"dbo:Settlement\")\n",
    "ST = Concept(singleton=\"<STRING>\")\n",
    "PO = Existential(\"dbo:postalCode\", ST)\n",
    "CU = Existential(\"dbo:country\", TO)\n",
    "for axiom in (TO, CO, ST, PO, CU):\n",
    "    print(repr(axiom), \"\\t\", axiom)\n",
    "    \n",
    "print(\"\\n==Axiomes composés==\")\n",
    "A1 = CO & PO\n",
    "A2 = CO & CU\n",
    "A3 = A1 | A2\n",
    "A4 = ~ST\n",
    "for axiom in (A1, A2, A3, A4):\n",
    "    print(repr(axiom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un axiome présente une méthode `holds_for()` qui permet de vérifier si une entité vérifie cet axiome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO.holds_for(kg.ent.to_id(\"dbr:Salaberry-de-Valleyfield\"), kg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
