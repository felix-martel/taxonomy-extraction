{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     3,
     14,
     25,
     39
    ]
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from libs.utils.params import Params\n",
    "\n",
    "params = Params(\n",
    "    size=Params(\n",
    "        # Sampling sizes\n",
    "        size=1000,\n",
    "        initial=4000,\n",
    "        decrease=0.9,\n",
    "        plateau=600\n",
    "    ),\n",
    "    # Random state\n",
    "    seed=None,\n",
    "    # Thresholds\n",
    "    threshold=Params(\n",
    "        adaptative=True,\n",
    "        opt=0.9,\n",
    "        initial=0.9,\n",
    "        min=0.6,\n",
    "        step=0.05,\n",
    "        expressive=0.5,\n",
    "        current=0.9,\n",
    "    ),\n",
    "    max_depth=4,\n",
    "    max_depth_step=0,\n",
    "    patterns=Params(\n",
    "        individuals=True,\n",
    "        existential=True,\n",
    "    ),\n",
    "    embeddings=\"toy\",\n",
    "    clustering=Params(\n",
    "        affinity=\"euclidean\",\n",
    "        linkage=\"ward\",\n",
    "    ),\n",
    "    metric=\"harmonic\",\n",
    "    max_axioms=2,\n",
    "    min_gain=0.08,\n",
    "    allow_child=False,\n",
    "    sort_axioms=False,\n",
    "    others=Params(\n",
    "        keep=True,\n",
    "        n=8, # Max number of candidates to keep\n",
    "        threshold=0.9, # % of the optimal score\n",
    "    ),\n",
    "    halting=Params(\n",
    "        min_size=30,\n",
    "        max_rec_steps=40,\n",
    "        max_clustering_steps=100,\n",
    "        max_extracted_depth=15,\n",
    "        memory_limit=110*1024**2 # gigabytes\n",
    "    ),\n",
    "    extra=Params(\n",
    "        active=True,\n",
    "        n=100,\n",
    "        reset_classes=True,\n",
    "        depth=20,\n",
    "        threshold=0.15\n",
    "    ),\n",
    "    record=Params(\n",
    "        save_taxonomy=True,\n",
    "        checkpoints=True,\n",
    "        checkpoint_every=100,\n",
    "        dirname=\"results/taxonomy/auto\",\n",
    "        name_pattern=\"taxonomy_{halting.max_clustering_steps}s_{timestamp:%m%d_%Hh%M}\"\n",
    "    ),\n",
    "    display=True\n",
    ")\n",
    "#params.record.taxname = params.record.name_pattern.format(**params)\n",
    "\n",
    "params.save(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triples: 100%|█████████████████████████████████████████████████████████████| 316114/316114 [00:02<00:00, 125380.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from libs.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph.from_dir(\"toy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54795, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libs.embeddings import load\n",
    "\n",
    "E = load(\"toy\")\n",
    "\n",
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:14:27 - INFO : Initialisation done.\n",
      "10:14:27 - INFO : STEP 0: starting with axiom ⊤\n",
      "10:14:28 - INFO : Subclasses found: ∃dbo:birthDate.{xsd:date}, ∃dbo:location.dbo:Location\n",
      "10:14:28 - INFO : STEP 1: starting with axiom ∃dbo:birthDate.{xsd:date}\n",
      "10:14:29 - INFO : Subclasses found: ∃dbo:deathPlace.dbo:Place, ∃dbo:birthPlace.dbo:Country\n",
      "10:14:29 - INFO : STEP 2: starting with axiom ∃dbo:location.dbo:Location\n",
      "10:14:30 - INFO : Subclasses found: ∃dbo:location.dbo:Country, ∃dbo:followingEvent.dbo:SocietalEvent\n",
      "10:14:30 - INFO : STEP 3: starting with axiom ∃dbo:deathPlace.dbo:Place\n",
      "10:14:32 - INFO : Subclasses found: ∃dbo:birthPlace.dbo:AdministrativeRegion, ∃foaf:surname.{<LABEL:en>}\n",
      "10:14:32 - INFO : STEP 4: starting with axiom ∃dbo:birthPlace.dbo:Country\n",
      "10:14:33 - INFO : Subclasses found: ∃dbo:deathPlace.dbo:Location, ∃dbo:number.{<STRING>}\n",
      "10:14:33 - INFO : STEP 5: starting with axiom ∃dbo:location.dbo:Country\n",
      "10:14:34 - INFO : Subclasses found: ∃dbo:fastestDriver.dbo:Person, ∃dbo:numberOfEmployees.{xsd:nonNegativeInteger}\n",
      "10:14:34 - INFO : STEP 6: starting with axiom ∃dbo:followingEvent.dbo:SocietalEvent\n",
      "10:14:34 - INFO : Subclasses found: ∃dbo:followingEvent.dbo:SportsEvent, ∃dbo:location.dbo:ArchitecturalStructure\n",
      "10:14:34 - INFO : STEP 7: starting with axiom ∃dbo:birthPlace.dbo:AdministrativeRegion\n",
      "10:14:35 - INFO : Subclasses found: ∃dbo:deathPlace.dbo:PopulatedPlace, ∃dbo:nationality.dbo:Place\n",
      "10:14:35 - INFO : STEP 8: starting with axiom ∃foaf:surname.{<LABEL:en>}\n",
      "10:14:36 - INFO : Subclasses found: ∃dbo:team.dbo:Agent, ∃dbo:birthPlace.dbo:City\n",
      "10:14:36 - INFO : STEP 9: starting with axiom ∃dbo:deathPlace.dbo:Location\n",
      "10:14:37 - INFO : Subclasses found: ∃dbo:deathPlace.dbo:Country, ∃dbo:birthPlace.dbo:Place\n",
      "                                                       ┌∃dbo:fastestDriver.dbo:Person\n",
      "                             ┌∃dbo:location.dbo:Country┤\n",
      "                             │                         └∃dbo:numberOfEmployees.{xsd:nonNegativeInteger}\n",
      "  ┌∃dbo:location.dbo:Location┤\n",
      "  │                          │                                     ┌∃dbo:followingEvent.dbo:SportsEvent\n",
      "  │                          └∃dbo:followingEvent.dbo:SocietalEvent┤\n",
      "  │                                                                └∃dbo:location.dbo:ArchitecturalStructure\n",
      " ⊤┤\n",
      "  │                                                     ┌∃dbo:number.{<STRING>}\n",
      "  │                         ┌∃dbo:birthPlace.dbo:Country┤\n",
      "  │                         │                           │                            ┌∃dbo:deathPlace.dbo:Country\n",
      "  │                         │                           └∃dbo:deathPlace.dbo:Location┤\n",
      "  │                         │                                                        └∃dbo:birthPlace.dbo:Place\n",
      "  └∃dbo:birthDate.{xsd:date}┤\n",
      "                            │                                                                  ┌∃dbo:deathPlace.dbo:PopulatedPlace\n",
      "                            │                         ┌∃dbo:birthPlace.dbo:AdministrativeRegion┤\n",
      "                            │                         │                                        └∃dbo:nationality.dbo:Place\n",
      "                            └∃dbo:deathPlace.dbo:Place┤\n",
      "                                                      │                          ┌∃dbo:team.dbo:Agent\n",
      "                                                      └∃foaf:surname.{<LABEL:en>}┤\n",
      "                                                                                 └∃dbo:birthPlace.dbo:City\n"
     ]
    }
   ],
   "source": [
    "import libs.expressive.extractor as exp\n",
    "from importlib import reload\n",
    "import libs.sampling as lsamp\n",
    "from libs.axiom import Existential, Concept\n",
    "\n",
    "reload(lsamp)\n",
    "reload(exp)\n",
    "\n",
    "\n",
    "relevant_ids = {h for h, rs in kg._h.items() if len(rs) > 3}\n",
    "sampler = lsamp.NaiveGraphSampler(kg, relevant_ids)\n",
    "\n",
    "\n",
    "extr = exp.ExpressiveExtractor(kg, params, sampler=sampler, verbose=\"INFO\")\n",
    "extr.init()\n",
    "extr.run(10)\n",
    "extr.T.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(clu.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "root = logging.getLogger(\"\")\n",
    "root.warning(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dbr:Yasunori_Nomura',\n",
       " 'dbr:Kagami_Yoshimizu',\n",
       " 'dbr:Tateo_Ozaki',\n",
       " 'dbr:Hikari_Okubo',\n",
       " 'dbr:Nabi_Tajima',\n",
       " 'dbr:Saeko_Kimura',\n",
       " 'dbr:Masahiko_Amakasu']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import libs.sampling as lsamp\n",
    "reload(lsamp)\n",
    "from libs.axiom import Existential, Concept\n",
    "\n",
    "relevant_ids = {h for h, rs in kg._h.items() if len(rs) > 3}\n",
    "sampler = lsamp.NaiveGraphSampler(kg, relevant_ids)\n",
    "axiom = Existential(\"dbo:nationality\", Concept(singleton=\"dbr:Japan\")) & Concept(\"dbo:Agent\")\n",
    "\n",
    "instances, size = sampler.sample(axiom, 10)\n",
    "\n",
    "kg.ent.to_uris(*instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kg.ent.idx.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(set(), 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = Existential(\"dbo:birthName\", Concept(singleton=\"<LABEL:en>\")) & Concept(\"dbo:Agent\")\n",
    "\n",
    "print(ax.holds_for(kg.ent.to_id(\"dbr:Kagami_Yoshimizu\"), kg))\n",
    "\n",
    "sampler.sample(ax, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isa = kg.rel.to_id(\"rdf:type\")\n",
    "rid = kg.rel.to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dbr:Valeriy_Vorobyov',\n",
       " 'dbr:Gornji_Mamići',\n",
       " 'dbr:Raphael_Samuel',\n",
       " 'dbr:Wyoming_Historic_District',\n",
       " 'dbr:Lakeridge,_Saskatoon__St._Luke_School__1',\n",
       " 'dbr:Portland_International_Airport_MAX_Station',\n",
       " 'dbr:Lough_Neagh',\n",
       " 'dbr:Kagami_Yoshimizu',\n",
       " 'dbr:Air_Nigeria',\n",
       " 'dbr:Akron,_Pennsylvania']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.ent.to_uris(*list(relevant_ids)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbr:Kagami_Yoshimizu\n",
      "\t rdf:type\n",
      "\t\t dbo:Agent\n",
      "\t\t dbo:Artist\n",
      "\t\t dbo:Person\n",
      "\t foaf:gender <LABEL:en>\n",
      "\t dbo:birthName <LABEL:en>\n",
      "\t dbo:nationality dbr:Japan\n",
      "\t dbo:birthPlace\n",
      "\t\t dbr:Saitama_Prefecture\n",
      "\t\t dbr:Japan\n",
      "\t\t dbr:Satte,_Saitama\n",
      "\t dbo:birthDate xsd:date\n"
     ]
    }
   ],
   "source": [
    "kg.print_relations(\"dbr:Kagami_Yoshimizu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3a70a1435c09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# extr.init()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Projet\\code\\helios_15042020\\libs\\expressive\\extractor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# CHOOSE: Here, start is the start axiom A (from which we'll sample entities) and parent is the parent axiom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;31m# (to which we'll attach newfound axioms)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_start_axiom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRemainderAxiom\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# TODO: check max. taxonomic depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projet\\code\\helios_15042020\\libs\\expressive\\extractor.py\u001b[0m in \u001b[0;36mget_start_axiom\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_axioms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'get_start_axiom' is not implemented yet when 'sort_axioms' is set to True\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munprocessed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxiom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "# extr.init()\n",
    "extr.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ca, cb = \"dbo:Athlete\", \"dbo:City\"\n",
    "size = 5\n",
    "\n",
    "relevant_ids = [h for h, rs in kg._h.items() if len(rs) > 5]\n",
    "\n",
    "def sample_from_class(cls, size, graph=kg, verbose=True):\n",
    "    clsid = graph.ent.to_id(cls)\n",
    "    instances = [x for x in relevant_ids if (x, graph.isaid, clsid) in graph]\n",
    "    if verbose and size > len(instances):\n",
    "        print(f\"WARNING: Can't sample {size} items out of {len(instances)} instances of class {cls}\")\n",
    "    size = min(size, len(instances))\n",
    "\n",
    "    return random.sample(instances, size)\n",
    "\n",
    "A = sample_from_class(ca, size)\n",
    "B = sample_from_class(cb, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inducer(entities=10, axioms=125)\n",
      "Finding axioms\n",
      "\n",
      "Step 0/3: 1 axioms to improve\n",
      "Improving __empty__...\n",
      "Coverage too low (0.00<0.85). Adding OR clauses...\n",
      "Specificity too low (0.00<0.85). Adding AND clauses...\n",
      "...250 results found\n",
      "\n",
      "Step 1/3: 5 axioms to improve\n",
      "Improving ∃dbo:isPartOf.dbo:AdministrativeRegion...\n",
      "Coverage too low (0.40<0.85). Adding OR clauses...\n",
      "...124 results found\n",
      "Improving ∃dbo:isPartOf.{dbr:Una_district}...\n",
      "Coverage too low (0.20<0.85). Adding OR clauses...\n",
      "...124 results found\n",
      "Improving ∃dbo:part.{dbr:Human_settlement}...\n",
      "Coverage too low (0.20<0.85). Adding OR clauses...\n",
      "...124 results found\n",
      "Improving ∃dbo:position.{dbr:Attacking_Midfielder}...\n",
      "Coverage too low (0.00<0.85). Adding OR clauses...\n",
      "Specificity too low (0.80<0.85). Adding AND clauses...\n",
      "...248 results found\n",
      "Improving ∃dbo:nationality.dbo:Place...\n",
      "Coverage too low (0.00<0.85). Adding OR clauses...\n",
      "Specificity too low (0.60<0.85). Adding AND clauses...\n",
      "...248 results found\n",
      "\n",
      "Step 2/3: 5 axioms to improve\n",
      "Improving ∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:isPartOf.{dbr:Una_district}...\n",
      "Coverage too low (0.60<0.85). Adding OR clauses...\n",
      "...123 results found\n",
      "Improving ∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:part.{dbr:Human_settlement}...\n",
      "Coverage too low (0.60<0.85). Adding OR clauses...\n",
      "...123 results found\n",
      "Improving ∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:isPartOf.dbo:AdministrativeRegion...\n",
      "Coverage too low (0.60<0.85). Adding OR clauses...\n",
      "...123 results found\n",
      "Improving ∃dbo:part.{dbr:Human_settlement}∨∃dbo:isPartOf.dbo:AdministrativeRegion...\n",
      "Coverage too low (0.60<0.85). Adding OR clauses...\n",
      "...123 results found\n",
      "Improving ∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:part.{dbr:Human_settlement}...\n",
      "Coverage too low (0.40<0.85). Adding OR clauses...\n",
      "...123 results found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>axiom</td><td>cov</td><td>spe</td><td>sco</td><td></td></tr><tr><td><b>0</b></td><td></td><td></td><td></td><td></td></tr><tr><td>∃dbo:isPartOf.dbo:AdministrativeRegion</td><td>0.40</td><td>1.00</td><td>0.70</td><td>0</td></tr><tr><td>∃dbo:isPartOf.{dbr:Una_district}</td><td>0.20</td><td>1.00</td><td>0.60</td><td>0</td></tr><tr><td>∃dbo:part.{dbr:Human_settlement}</td><td>0.20</td><td>1.00</td><td>0.60</td><td>0</td></tr><tr><td>∃dbo:position.{dbr:Attacking_Midfielder}</td><td>0.00</td><td>0.80</td><td>0.40</td><td>0</td></tr><tr><td>∃dbo:nationality.dbo:Place</td><td>0.00</td><td>0.60</td><td>0.30</td><td>0</td></tr><tr><td><b>1</b></td><td></td><td></td><td></td><td></td></tr><tr><td>∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:isPartOf.{dbr:Una_district}</td><td>0.60</td><td>1.00</td><td>0.80</td><td>1</td></tr><tr><td>∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:part.{dbr:Human_settlement}</td><td>0.60</td><td>1.00</td><td>0.80</td><td>1</td></tr><tr><td>∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:isPartOf.dbo:AdministrativeRegion</td><td>0.60</td><td>1.00</td><td>0.80</td><td>1</td></tr><tr><td>∃dbo:part.{dbr:Human_settlement}∨∃dbo:isPartOf.dbo:AdministrativeRegion</td><td>0.60</td><td>1.00</td><td>0.80</td><td>1</td></tr><tr><td>∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:part.{dbr:Human_settlement}</td><td>0.40</td><td>1.00</td><td>0.70</td><td>1</td></tr><tr><td><b>2</b></td><td></td><td></td><td></td><td></td></tr><tr><td>∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:isPartOf.dbo:PopulatedPlace</td><td>1.00</td><td>1.00</td><td>1.00</td><td>2</td></tr><tr><td>∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:part.{dbr:Human_settlement}∨∃dbo:isPartOf.dbo:PopulatedPlace</td><td>1.00</td><td>1.00</td><td>1.00</td><td>2</td></tr><tr><td>∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:isPartOf.dbo:PopulatedPlace</td><td>1.00</td><td>1.00</td><td>1.00</td><td>2</td></tr><tr><td>∃dbo:part.{dbr:Human_settlement}∨∃dbo:isPartOf.dbo:AdministrativeRegion∨∃dbo:isPartOf.dbo:PopulatedPlace</td><td>1.00</td><td>1.00</td><td>1.00</td><td>2</td></tr><tr><td>∃dbo:isPartOf.{dbr:Una_district}∨∃dbo:part.{dbr:Human_settlement}∨∃dbo:isPartOf.dbo:PopulatedPlace</td><td>1.00</td><td>1.00</td><td>1.00</td><td>2</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import libs.axiom_extraction as lae\n",
    "from importlib import reload\n",
    "\n",
    "lae = reload(lae)\n",
    "\n",
    "ind = lae.Inducer(B, A, kg, threshold=0.0)\n",
    "\n",
    "print(ind)\n",
    "\n",
    "res = ind.find(allow_neg=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbr:Henri_Cochet\n",
      "\t rdf:type\n",
      "\t\t dbo:TennisPlayer\n",
      "\t\t dbo:Athlete\n",
      "\t\t dbo:Agent\n",
      "\t\t dbo:Person\n"
     ]
    }
   ],
   "source": [
    "kg.print_relations(\"dbr:Henri_Cochet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33830 dbr:Lake_of_Two_Mountains\n",
      "1401 dbr:La_Sauzière-Saint-Jean\n",
      "21573 dbr:Mount_Helen,_Victoria\n",
      "33700 dbr:Incheon\n",
      "27706 dbr:Farino\n",
      "39428 dbr:Kissidougou_Prefecture\n",
      "13376 dbr:Las_Piedras,_Artigas\n",
      "1993 dbr:Quilmes\n",
      "34 dbr:Munich\n",
      "46924 dbr:Yazd\n"
     ]
    }
   ],
   "source": [
    "for i in B[:10]:\n",
    "    print(i, kg.ent.to_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Can't sample 100 items out of 22 instances of class dbo:TennisPlayer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23735,\n",
       " 10003,\n",
       " 19116,\n",
       " 33,\n",
       " 3242,\n",
       " 5270,\n",
       " 9621,\n",
       " 11046,\n",
       " 8582,\n",
       " 24551,\n",
       " 22815,\n",
       " 25026,\n",
       " 31238,\n",
       " 28302,\n",
       " 45888,\n",
       " 2906,\n",
       " 8416,\n",
       " 7846,\n",
       " 4370,\n",
       " 24435,\n",
       " 30291,\n",
       " 16864]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_ids = [h for h, rs in kg._h.items() if len(rs) > 5]\n",
    "\n",
    "def sample_from_class(cls, size, graph=kg, verbose=True):\n",
    "    clsid = graph.ent.to_id(cls)\n",
    "    instances = [x for x in relevant_ids if (x, graph.isaid, clsid) in graph]\n",
    "    if verbose and size > len(instances):\n",
    "        print(f\"WARNING: Can't sample {size} items out of {len(instances)} instances of class {cls}\")\n",
    "    size = min(size, len(instances))\n",
    "\n",
    "    return random.sample(instances, size)\n",
    "\n",
    "sample_from_class(\"dbo:TennisPlayer\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_from_class(cls, size, graph=kg):\n",
    "    return random.sample([h for h, _, _ in graph.find_triples(r=graph.isaid, t=graph.ent.to_id(cls))], size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
