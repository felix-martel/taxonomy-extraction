{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triples: 100%|██████████| 316114/316114 [00:02<00:00, 123138.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from libs import embeddings\n",
    "from libs.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph.from_dir(\"toy\")\n",
    "#E = embeddings.load(\"toy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbr:Anthony_Warde\n",
      "\t dbo:birthDate xsd:date\n",
      "\t rdf:type\n",
      "\t\t dbo:Agent\n",
      "\t\t dbo:Person\n",
      "\t dbo:activeYearsStartYear xsd:gYear\n",
      "\t dbo:activeYearsEndYear xsd:gYear\n",
      "\t dbo:imdbId <STRING>\n",
      "\t dbo:birthPlace dbr:Pennsylvania\n",
      "\t foaf:givenName <LABEL:en>\n",
      "\t dbo:birthYear xsd:gYear\n",
      "\t dbo:occupation dbr:Film\n",
      "\t dbo:deathDate xsd:date\n",
      "\t dbo:deathPlace\n",
      "\t\t dbr:California\n",
      "\t\t dbr:Hollywood\n",
      "\t foaf:surname <LABEL:en>\n",
      "\t foaf:gender <LABEL:en>\n",
      "\t dbo:deathYear xsd:gYear\n"
     ]
    }
   ],
   "source": [
    "ename = \"dbr:Anthony_Warde\"\n",
    "eid = kg.ent.to_id(ename)\n",
    "\n",
    "kg.print_relations(ename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 10 instances out of 47694\n",
      "dbr:Kolding\n",
      "dbr:Gmina_Sławno,_Łódź_Voivodeship\n",
      "dbr:Cadiz,_Kentucky\n",
      "dbr:Jafarbay-ye_Jonubi_Rural_District\n",
      "dbr:Colegio_Niño_Jesús_de_Praga\n",
      "dbr:Lev_Kamenev\n",
      "dbr:Andilanatoby\n",
      "dbr:AC_Sparta_Praha_(women)\n",
      "dbr:Whiting,_Vermont\n",
      "dbr:The_Bahamas\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import libs.sampling.instance_sampling as samp\n",
    "reload(samp)\n",
    "\n",
    "samp.set_graph(kg)\n",
    "\n",
    "instances, n = samp.sample_any(10)\n",
    "print(f\"Sampled {len(instances)} instances out of {n}\")\n",
    "print(*map(kg.ent.to_name, instances), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 7 instances out of 7 for axiom '∃dbo:deathPlace.{dbr:California}∧∃dbo:deathYear.⊤'\n",
      "dbr:Ruth_Roland\n",
      "dbr:A._A._Allen\n",
      "dbr:Albert_R._Broccoli\n",
      "dbr:Brad_Renfro\n",
      "dbr:Anthony_Warde\n",
      "dbr:Harvey_Lembeck\n",
      "dbr:Isaac_Newton_Van_Nuys\n"
     ]
    }
   ],
   "source": [
    "# import libs.axiom.atomic as atoms\n",
    "from libs.axiom import Concept, Existential\n",
    "#reload(atoms)\n",
    "reload(samp)\n",
    "#Existential, Concept\n",
    "samp.set_graph(kg)\n",
    "\n",
    "Place = Concept(singleton=\"dbr:California\")\n",
    "a = Existential(\"dbo:deathPlace\", Place)\n",
    "b = Existential(\"dbo:deathYear\", None)\n",
    "\n",
    "instances, n = samp.sample_from(a & b, 10)\n",
    "print(f\"Sampled {len(instances)} instances out of {n} for axiom '{a & b}'\")\n",
    "print(*map(kg.ent.to_name, instances), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbr:California\n",
      "\t rdf:type\n",
      "\t\t dbo:Location\n",
      "\t\t dbo:Place\n",
      "\t\t dbo:Region\n",
      "\t\t dbo:PopulatedPlace\n",
      "\t\t dbo:AdministrativeRegion\n"
     ]
    }
   ],
   "source": [
    "kg.print_relations(\"dbr:California\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "for h, t in kg.iter_head_tails(kg.rel.to_id(\"rdf:type\"), as_string=True):\n",
    "    c[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sample_instances in module libs.graph.knowledge_graph:\n",
      "\n",
      "sample_instances(n, from_type='owl:Thing', except_type=None, type_rel='rdf:type', as_string=False, force_size=True, exclude_ids=None) method of libs.graph.knowledge_graph.KnowledgeGraph instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(kg.sample_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dbo:Agent',\n",
       " 'dbo:Athlete',\n",
       " 'dbo:Event',\n",
       " 'dbo:Location',\n",
       " 'dbo:Organisation',\n",
       " 'dbo:Person',\n",
       " 'dbo:PopulatedPlace',\n",
       " 'dbo:Settlement',\n",
       " 'dbo:SocietalEvent',\n",
       " 'dbo:SportsEvent'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {cls for cls, count in c.most_common(n_classes + 1) if cls != \"dbo:Place\"}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ┌dbo:SocietalEvent\n",
      "     ┌dbo:Event┤\n",
      "     │         └dbo:SportsEvent\n",
      " root┤\n",
      "     │         ┌dbo:Organisation\n",
      "     ├dbo:Agent┤\n",
      "     │         └dbo:Person┐\n",
      "     │                    └dbo:Athlete\n",
      "     └dbo:Location┐\n",
      "                  └dbo:PopulatedPlace┐\n",
      "                                     └dbo:Settlement\n"
     ]
    }
   ],
   "source": [
    "raw_axioms = \"\"\"\n",
    "dbo:Athlete dbo:Person\n",
    "dbo:Person dbo:Agent\n",
    "dbo:Organisation dbo:Agent\n",
    "dbo:SocietalEvent dbo:Event\n",
    "dbo:SportsEvent dbo:Event\n",
    "dbo:Settlement dbo:PopulatedPlace\n",
    "dbo:PopulatedPlace dbo:Location\n",
    "\"\"\"\n",
    "\n",
    "axioms = [tuple(line.split()) for line in raw_axioms.split(\"\\n\")[1:-1]]\n",
    "axioms\n",
    "\n",
    "from libs.taxonomy import Taxonomy\n",
    "\n",
    "\n",
    "T = Taxonomy.from_axioms(axioms, add_root=\"root\")\n",
    "T.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbo:Location dbo:Agent dbo:Event dbo:SportsEvent dbo:Place dbo:PopulatedPlace dbo:Person dbo:SocietalEvent dbo:Organisation dbo:Settlement\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from libs.dataset import Dataset\n",
    "\n",
    "n_classes = 10\n",
    "n_entities = 200\n",
    "classes = {cls for cls, count in c.most_common(n_classes + 1) if cls != \"dbo:Place\"}\n",
    "\n",
    "used_indices = set()\n",
    "indices = []\n",
    "labels = []\n",
    "name2cls, cls2name = dict(), dict()\n",
    "\n",
    "for name in classes:\n",
    "    cls = len(name2cls)\n",
    "    name2cls[name] = cls\n",
    "    cls2name[cls] = name\n",
    "    \n",
    "    for instance in kg.sample_instances(n_entities, from_type=name, exclude_ids=used_indices):\n",
    "        used_indices.add(instance)\n",
    "        indices.append(instance)\n",
    "        labels.append(cls)\n",
    "        \n",
    "axioms = {\n",
    "    \"dbo:Athlete\", \"dbo:Person\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311330 mots trouvés\n"
     ]
    }
   ],
   "source": [
    "# 1: lire les mots\n",
    "with open(\"dico.txt\", \"r\", encoding=\"utf8\") as fichier:\n",
    "    dico = []\n",
    "    for mot in fichier.read().split(\"\\n\"):\n",
    "        # On enlève les mots trop courts\n",
    "        if len(mot) > 6:\n",
    "            dico.append(mot)\n",
    "            \n",
    "print(len(dico), \"mots trouvés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mot choisi: lipothymies\n"
     ]
    }
   ],
   "source": [
    "# 2: choisir un mot au hasard\n",
    "from random import choice\n",
    "from unidecode import unidecode as deaccent\n",
    "\n",
    "mot = choice(dico)\n",
    "mot = deaccent(mot)\n",
    "\n",
    "print(\"Mot choisi:\", mot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l _ _ _ _ _ _ _ _ _ s\n"
     ]
    }
   ],
   "source": [
    "début = mot[0]\n",
    "fin = mot[-1]\n",
    "\n",
    "mot_à_afficher = début + \"_\" * (len(mot) - 2) + fin\n",
    "\n",
    "print(*mot_à_afficher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mot_à_afficher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4c48e1456fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0métape_actuelle\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnb_étapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0métape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"  (étape \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0métape_actuelle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" sur \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_étapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\")\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmot_à_afficher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0métape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mlettre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlettre\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlettres_utilisées\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mot_à_afficher' is not defined"
     ]
    }
   ],
   "source": [
    "nb_étapes = 10\n",
    "étape_actuelle = 0\n",
    "lettres_utilisées = []\n",
    "\n",
    "while étape_actuelle < nb_étapes:\n",
    "    étape = \"  (étape \" + str(étape_actuelle) + \" sur \" + str(nb_étapes) + \")\"\n",
    "    print(*mot_à_afficher, étape)\n",
    "    lettre = input()\n",
    "    if lettre in lettres_utilisées:\n",
    "        print(\"la lettre\", lettre, \"a déjà été utilisée\")\n",
    "    else:\n",
    "        nouveau_mot = \"\"\n",
    "        for i in range(len(mot)):\n",
    "            vraie_lettre = mot[i]\n",
    "            if vraie_lettre == lettre:\n",
    "                nouveau_mot += lettre\n",
    "            else:\n",
    "                nouveau_mot += mot_à_afficher[i]\n",
    "            \n",
    "        étape_actuelle += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 311330 words\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from unidecode import unidecode\n",
    "\n",
    "# 1: read word list\n",
    "min_length = 7\n",
    "with open(\"dico.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    words = [word for word in f.read().split(\"\\n\") if len(word) >= min_length]\n",
    "print(f\"Found {len(words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "trash = StringIO()\n",
    "\n",
    "\n",
    "def get_insult():\n",
    "    template = \"You've been hanged, you <adjective> <adjective min=1 max=3 id=adj1> <amount> of <adjective min=1 max=3> <animal> <animal_part>\"\n",
    "    r = requests.get(\"https://insult.mattbas.org/api/insult\", params=dict(template=template))\n",
    "    if r.status_code == 200:\n",
    "        return r.text\n",
    "    else:\n",
    "        return \"You've been hanged! We can't insult you right now because our insult API seems to be broken. Please try being insulted again in a few minutes.\"\n",
    " \n",
    "def update_current(letter, current, reference):\n",
    "    new_word = [l_true if normalize(l_true) == letter else l_curr for l_true, l_curr in zip(reference, current)]\n",
    "    return \"\".join(new_word)\n",
    "\n",
    "def normalize(s):\n",
    "    return unidecode(str(s).lower())\n",
    "\n",
    "def play_game(word=None, max_step=5, debug=False):\n",
    "    if word is None:\n",
    "        word = choice(words)\n",
    "    \n",
    "    TRUE_WORD = word\n",
    "    if not TRUE_WORD.isalpha():\n",
    "        raise ValueError(f\"'{TRUE_WORD}' is not a valid word\")\n",
    "        \n",
    "    # word = unidecode(TRUE_WORD)\n",
    "    inner = normalize(TRUE_WORD[1:-1])\n",
    "    curr_word = TRUE_WORD[0] + \"_\" * len(inner) + TRUE_WORD[-1]\n",
    "    \n",
    "    if debug:\n",
    "        print(TRUE_WORD, inner, curr_word)\n",
    "\n",
    "    print(\"# GAME START #\")\n",
    "    print(*curr_word)\n",
    "\n",
    "    won = False\n",
    "    RUNNING = \"running\"\n",
    "    WON = \"won\"\n",
    "    DNF = \"quit\"\n",
    "    LOST = \"lost\"\n",
    "    status = RUNNING\n",
    "    \n",
    "    step = 0\n",
    "    used_letters = set()\n",
    "\n",
    "    while step < max_step:\n",
    "        letter = input(f\"\\n({step}/{max_step})\")\n",
    "        letter = normalize(letter)\n",
    "        if letter in (\"quit\", \"stop\"):\n",
    "            status = DNF\n",
    "            break\n",
    "        if letter in used_letters:\n",
    "            print(f\"Letter '{letter}' has already been used\")\n",
    "            continue\n",
    "        used_letters.add(letter)\n",
    "        count = inner.count(letter)\n",
    "        if not count:\n",
    "            print(f\"Wrong. Letter '{letter}' is not in word\")\n",
    "            step += 1\n",
    "            continue\n",
    "        print(f\"{count} occurences found for letter '{letter}'\")\n",
    "        curr_word = update_current(letter, curr_word, TRUE_WORD)\n",
    "        if curr_word == TRUE_WORD:\n",
    "            print(*curr_word)\n",
    "            print(f\"You won!\")\n",
    "            won = True\n",
    "            status = WON\n",
    "            break\n",
    "        else:\n",
    "            used = \"\".join(sorted(used_letters))\n",
    "            print(*curr_word, f\"\\t used: {used}\")\n",
    "    else:\n",
    "        status = LOST\n",
    "        print(get_insult())\n",
    "        print(f\"The word was '{word}'\")\n",
    "    \n",
    "    result = dict(\n",
    "        won=won,\n",
    "        status=status,\n",
    "        steps=step,\n",
    "        word=TRUE_WORD,\n",
    "        letters=used_letters\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def play_games(n_games=float(\"inf\"), max_step=5):\n",
    "    curr_game = 0\n",
    "    results = []\n",
    "    n_wins = 0\n",
    "    while curr_game < n_games:\n",
    "        curr_game += 1\n",
    "        res = play_game(max_step=max_step)\n",
    "        if res[\"won\"]:\n",
    "            n_wins += 1\n",
    "        results.append(res)\n",
    "        if curr_game < n_games:\n",
    "            x = input(\"Keep playing? [y]/n\")\n",
    "            if x == \"n\":\n",
    "                break\n",
    "    print(f\"\\nYou won {n_wins} games out of {curr_game} ({100*n_wins/curr_game:.1f}%)\")\n",
    "    return results\n",
    "\n",
    "res = play_games(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'You lost, you savage lesser hostile plate of slimy pig slime'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_insult():\n",
    "    template = \"You lost, you <adjective> <adjective min=1 max=3 id=adj1> <amount> of <adjective min=1 max=3> <animal> <animal_part>\"\n",
    "    r = requests.get(\"https://insult.mattbas.org/api/insult\", params=dict(template=template))\n",
    "    if r.status_code == 200:\n",
    "        return r.content\n",
    "    else:\n",
    "        return \"You lost! We can't insult you right now because our insult API seems to be broken. Please try being insulted again in a few minutes.\"\n",
    "    \n",
    "get_insult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You lost, you wicked toxic pile of clumsy lizard slime'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trempèrent tremperent remperen t________t\n"
     ]
    }
   ],
   "source": [
    "max_step = 8\n",
    "step = 0\n",
    "used_letters = set()\n",
    "while step < max_step:\n",
    "    letter = input(f\"({step}/{max_step})\")\n",
    "    if letter in (\"quit\", \"stop\"):\n",
    "        break\n",
    "    if letter in used_letters:\n",
    "        print(f\"Letter '{letter}' has already been used\")\n",
    "        continue\n",
    "    used_letters.add(letter)\n",
    "    count = inner.count(letter)\n",
    "    if not count:\n",
    "        print(f\"Wrong. Letter '{letter}' is not in word\")\n",
    "        step += 1\n",
    "        continue\n",
    "    print(f\"{count} occurences found for letter '{letter}'\")\n",
    "    curr_word = \"\".join(letter if letter == true_letter else curr_letter for true_letter, curr_letter in zip(word, curr_word))\n",
    "    if curr_word == word:\n",
    "        print(*curr_word)\n",
    "        print(f\"You won!\")\n",
    "        n_won += 1\n",
    "    else:\n",
    "        used = \"\".join(sorted(used_letters))\n",
    "        print(*curr_word, f\"\\t used: {used}\")\n",
    "else:\n",
    "    print(f\"You've been hanged! The word was '{word}'\")\n",
    "n_games += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = choice(words)\n",
    "inner = word[1:-1]\n",
    "curr_word = word[0] + \"_\" * (len(inner)) + word[-1]\n",
    "\n",
    "print(\"# GAME START #\")\n",
    "print(*curr_word)\n",
    "\n",
    "n_games = 0\n",
    "n_won = 0\n",
    "\n",
    "max_step = 8\n",
    "step = 0\n",
    "used_letters = set()\n",
    "while step < max_step:\n",
    "    letter = input(f\"({step}/{max_step})\")\n",
    "    if letter in used_letters:\n",
    "        print(f\"Letter '{letter}' has already been used\")\n",
    "        continue\n",
    "    used_letters.add(letter)\n",
    "    count = inner.count(letter)\n",
    "    if not count:\n",
    "        print(f\"Wrong. Letter '{letter}' is not in word\")\n",
    "        step += 1\n",
    "        continue\n",
    "    print(f\"{count} occurences found for letter '{letter}'\")\n",
    "    curr_word = \"\".join(letter if letter == true_letter else curr_letter for true_letter, curr_letter in zip(word, curr_word))\n",
    "    if curr_word == word:\n",
    "        print(*curr_word)\n",
    "        print(f\"You won!\")\n",
    "        n_won += 1\n",
    "    else:\n",
    "        used = \"\".join(sorted(used_letters))\n",
    "        print(*curr_word, f\"\\t used: {used}\")\n",
    "else:\n",
    "    print(f\"You've been hanged! The word was '{word}'\")\n",
    "n_games += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dereglasse', 'ereglass', 'd________e')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = choice(words)\n",
    "inner = word[1:-1]\n",
    "curr_word = word[0] + \"_\" * (len(inner)) + word[-1]\n",
    "\n",
    "word, inner, curr_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
